{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install git+https://github.com/huggingface/diffusers.git\n",
    "!pip install diffusers transformers gradio accelerate bitsandbytes datasets --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "%env MODEL_NAME=stabilityai/stable-diffusion-2-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Import pustaka yang dibutuhkan\n",
    "from diffusers import StableDiffusionPipeline\n",
    "from transformers import CLIPTextModel, CLIPTokenizer\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import os\n",
    "\n",
    "# Menampilkan versi dan detail torch\n",
    "!pip show torch\n",
    "\n",
    "# Memuat tokenizer dan model teks dari CLIP (transformers)\n",
    "tokenizer = CLIPTokenizer.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "text_model = CLIPTextModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "\n",
    "# Fungsi untuk menghasilkan embeddings teks dari prompt\n",
    "def get_text_embeddings(prompt):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        text_embeddings = text_model(**inputs).last_hidden_state\n",
    "    return text_embeddings\n",
    "\n",
    "# Memuat pipeline Stable Diffusion\n",
    "pipe = StableDiffusionPipeline.from_pretrained(os.getenv('MODEL_NAME'), torch_dtype=torch.float16)\n",
    "pipe = pipe.to(\"cuda\")\n",
    "\n",
    "# Prompt untuk menghasilkan gambar\n",
    "prompt = \"A man with a mustache and a beard in green armor\"\n",
    "\n",
    "# Menghasilkan embeddings teks dari prompt (opsional)\n",
    "text_embeddings = get_text_embeddings(prompt)\n",
    "\n",
    "# Menghasilkan gambar dari prompt menggunakan pipeline\n",
    "image = pipe(prompt).images[0]\n",
    "\n",
    "# Menampilkan hasil gambar\n",
    "print(\"[PROMPT]:\", prompt)\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Flush the GPU memory to be able to run the training\n",
    "del pipe\n",
    "del image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!git clone https://huggingface.co/datasets/nikkoyudha/dynasty_warriors_characters\n",
    "!git clone https://github.com/huggingface/diffusers.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install accelerate\n",
    "!pip install datasets\n",
    "!pip install bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "%env MODEL_NAME=stabilityai/stable-diffusion-2-1\n",
    "%env dataset_name=nikkoyudha/dynasty_warriors_characters\n",
    "# No need to train the model for long to see meaningful results.\n",
    "%env max_training_epochs = 1250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# The --use_8bit_adam flag is crucial to be able to train on the T4 GPU which has only 15GB of memory\n",
    "!accelerate launch diffusers/examples/text_to_image/train_text_to_image.py \\\n",
    "  --pretrained_model_name_or_path=$MODEL_NAME \\\n",
    "  --dataset_name=$dataset_name \\\n",
    "  --use_ema \\\n",
    "  --use_8bit_adam \\\n",
    "  --resolution=512 --center_crop --random_flip \\\n",
    "  --train_batch_size=1 \\\n",
    "  --gradient_accumulation_steps=4 \\\n",
    "  --gradient_checkpointing \\\n",
    "  --mixed_precision=\"fp16\" \\\n",
    "  --max_train_steps=$max_training_epochs \\\n",
    "  --learning_rate=1e-05 \\\n",
    "  --max_grad_norm=1 \\\n",
    "  --lr_scheduler=\"constant\" --lr_warmup_steps=0 \\\n",
    "  --output_dir=\"test-1-nikko\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Menampilkan versi dan detail torch\n",
    "!pip show torch\n",
    "\n",
    "# Memuat tokenizer dan model teks dari CLIP (transformers)\n",
    "tokenizer = CLIPTokenizer.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "text_model = CLIPTextModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "\n",
    "# Fungsi untuk menghasilkan embeddings teks dari prompt\n",
    "def get_text_embeddings(prompt):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        text_embeddings = text_model(**inputs).last_hidden_state\n",
    "    return text_embeddings\n",
    "\n",
    "pipe = StableDiffusionPipeline.from_pretrained('test-1-nikko', torch_dtype=torch.float16)\n",
    "pipe = pipe.to(\"cuda\")\n",
    "prompt = \"A man with a mustache and a beard in green armor\"\n",
    "\n",
    "# Menghasilkan embeddings teks dari prompt (opsional)\n",
    "text_embeddings = get_text_embeddings(prompt)\n",
    "\n",
    "# Menghasilkan gambar dari prompt menggunakan pipeline\n",
    "image = pipe(prompt).images[0]\n",
    "\n",
    "# Menampilkan hasil gambar\n",
    "print(\"[PROMPT]:\", prompt)\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
